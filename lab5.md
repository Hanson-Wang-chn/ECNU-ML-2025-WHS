# 实验五：决策树

### 实验目的：

+ 理解决策树的基本原理。
+ 学会使用Python中的库实现决策树模型，理解ID3、CART 决策树算法，理解决策树预剪枝、后剪枝技巧。
+ 掌握数据预处理、模型训练、评估流程和参数调优的基本步骤。

### 实验环境：

+ Python 3.x
+ 主要库：

  - Scikit-learn库
  - NumPy
  - Matplotlib

### 实验内容：

1. **基于鸢尾花数据集，运用ID3和CART算法构建决策树进行分类**
   + 从 `sklearn.datasets` 加载鸢尾花数据集，理解数据的基本结构和特征，包括样本数、特征类型和标签分布。
   + 进行数据分割，将数据集划分为训练集和测试集，注意**数据平衡**问题，训练集和测试集比例为 7:3，划分随机种子42。
   + 利用 `sklearn.tree.DecisionTreeClassifier`，分别使用`entropy`和`gini`参数作为节点分裂标准，根据鸢尾花的花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性构造决策树进行分类，random_state=42。
   + 输出两类分类标准下模型在验证集上的accuracy，并使用plot_tree绘制决策树。
   + 绘制PR曲线、ROC曲线并计算$F_1$值  
2. **基于鸢尾花数据集，使用决策树的预剪枝技巧**
   + 从 `sklearn.datasets` 加载鸢尾花数据集，理解数据的基本结构和特征，包括样本数、特征类型和标签分布。
   + 进行数据分割，将数据集划分为训练集和测试集，注意**数据平衡**问题，训练集和测试集比例为 7:3，划分随机种子42。
   + 利用 `sklearn.tree.DecisionTreeClassifier` 根据鸢尾花的花瓣长度，花瓣宽度2个属性构造决策树进行分类，random_state=42。
   + 利用 `max_depth`属性限制树的最大深度，进行预剪枝，并查看决策树在不同最大深度下的性能表现。
   + ```max_depth in [2, 4, 5]```
   + 输出模型在验证集上的accuracy，并使用plot_tree绘制决策树。
   + 绘制PR曲线、ROC曲线并计算$F_1$值。
3. **基于鸢尾花数据集，使用决策树的后剪枝技巧**
   + 从 `sklearn.datasets` 加载鸢尾花数据集，理解数据的基本结构和特征，包括样本数、特征类型和标签分布。
   + 进行数据分割，将数据集划分为训练集和测试集，注意**数据平衡**问题，训练集和测试集比例为 7:3，划分随机种子11。
   + 利用 `sklearn.tree.DecisionTreeClassifier` 根据鸢尾花的花瓣长度，花瓣宽度2个属性构造决策树进行分类，random_state=35。
   + 利用 `ccp_alpha` 控制决策树的复杂程度，并通过 `GridSearchCV ` 交叉验证来选择最佳的 `ccp_alpha` 值，以获得更好的模型性能。
   + 输出模型在验证集上的accuracy，并使用plot_tree绘制决策树。
   + 绘制PR曲线、ROC曲线并计算$F_1$值。

### 数据集

- 数据集使用 `sklearn` 自带的鸢尾花数据集。

### 要求：

- **实验报告**：完成实验后，撰写实验报告，实验报告中应包含实验主要步骤的 Python 代码，并加以注释说明。
- **结果可视化**：使用 `matplotlib` 对模型的预测结果进行可视化处理，展示结果和决策边界并绘制对应图表。

### 需提交：

- **实验报告**：详细描述实验过程、结果和分析的文档。报告应包括实验目的、内容、步骤、结果分析及可视化图表。
